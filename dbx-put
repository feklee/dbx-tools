#!/bin/bash

source "`dirname $0`/init.sh"

set -o pipefail

function store-hash {
    touch "$HASH_DIR/$HASH"
}

function compute-md5 {
    {
        stat "$FILE" && cat "$FILE"
    } | b2sum
}

function compute-hash {
    MD5SUM=`compute-md5` || \
        exit-on-error "Cannot compute hash for $FILE"
    HASH=${MD5SUM%% *}
}

function test-hash-exists {
    test -f "$HASH_DIR/$HASH"
}

function test-skip-file {
    test-option-enabled a && return 1 
    test-hash-exists
}

function create-hash-dir {
    HASH_DIR="$DOT_DIR/hashes"
    mkdir -p "$HASH_DIR" || \
        exit-on-error "Cannot create $HASH_DIR"
}

START_PWD="$PWD"

OPTIONS[a]="download all, i.e. never skip previously downloaded files"
NON_OPTION_ARGS="PATH"
DESCRIPTION=$(cat <<EOF
Upload PATH to the Dropbox. If PATH is a directory, upload its
contents recursively.

By comparing hashes, only files that have changed are uploaded. If a
file's meta data has changed, such as its name, it will be uploaded as
well.
EOF
           )
parse-options "$@"
shift $((OPTIND-1))
P="$1"
shift && test -n "$P" || exit-on-missing-args

create-hash-dir

ABSOLUTE_LOCAL_PATH=`realpath -m "$P"`

test-in-dbx-home "$ABSOLUTE_LOCAL_PATH" || \
    exit-on-error "Path not in \$DBX_HOME"

DBX_PATH=${ABSOLUTE_LOCAL_PATH##$DBX_HOME/}

cd "$DBX_HOME"
find -L "$DBX_PATH" -type f | \
    while read FILE; do
        ABS_LOCAL_FILE=`local-path "$FILE"`
        LOCAL_FILE="${ABS_LOCAL_FILE##$START_PWD/}"
        compute-hash
        if test-skip-file; then
            echo "Skipping previously uploaded $LOCAL_FILE"
        else
            dbxcli put "$FILE" "$FILE" || \
                exit-on-error "Failure uploading $LOCAL_FILE"
            echo "Success uploading $LOCAL_FILE"
            store-hash
        fi
    done
